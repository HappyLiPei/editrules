%\VignetteIndexEntry{Error localization for numerical and categorical edits as a mixed integer problem}
\documentclass[11pt, fleqn, a4paper]{article}
%\usepackage{inconsolata}
\usepackage[english]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{array}
\usepackage{natbib}
%\usepackage{algorithm}
%\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage{threeparttable}
\usepackage{makeidx}
\makeindex

\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\Lor}{\lor}
\DeclareMathOperator*{\Land}{\land}
\DeclareMathOperator{\ocup}{\cup}
\DeclareMathOperator{\ocap}{\cap}

\newcommand{\packageversion}{{\sf 2.5}}
\newcommand{\code}[1]{\textsf{#1}}
\newcommand{\R}{\code{R}} %% call as \R{} to avoid extra spaces.

\renewcommand{\mathbf}[1]{\ensuremath{\boldsymbol{#1}}}

\usepackage{float} 
\floatstyle{boxed}
\newfloat{Rcode}{t!}{rco}
\floatname{Rcode}{{\rm Figure}}
\makeatletter
\renewcommand{\fnum@Rcode}{%
%% make Rcound count and look like a figure.
%    \addtocounter{figure}{1}
    \setcounter{Rcode}{\value{figure}}
    \addtocounter{Rcode}{1}
    \rm Figure~\arabic{Rcode}% <- avoid space before ':'
}
\makeatother


% stimulate latex to put multiple floats on a page.
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{3}
\setcounter{dbltopnumber}{2}
\renewcommand{\topfraction}{.9}
\renewcommand{\textfraction}{.1}
\renewcommand{\bottomfraction}{.75}
\renewcommand{\floatpagefraction}{.9}
\renewcommand{\dblfloatpagefraction}{.9}
\renewcommand{\dbltopfraction}{.9}


\hyphenation{
    time-stamp 
    se-pa-ra-te-ly
    ge-ne-ra-li-zed
    e-dit-rules
}

<<init, echo=FALSE, results='hide', message=FALSE>>=
library(editrules)
#library(xtable)
@

\title{Error localization as a mixed integer problem with the {\tt editrules} package\\
{\small package version \Sexpr{packageVersion("editrules")}}}
\author{Edwin de Jonge and Mark van der Loo}
\begin{document}
\maketitle
\begin{abstract}
Error localization is the problem of finding out which fields in raw data
records contain erroneous values. The \code{editrules} extension package for
the \R{} environment for statistical computing was recently extended with a module
that allows for error localization based on a mixed integer programming
formulation (mip). In this paper we describe the mip formulation of the error
localization problem for the case of numerical, categorical, or mixed numerical
and categorical datasets. The new module is benchmarked against a previously
available module, which is based on a branch-and-bound approach. The benchmark
shows that the mip-based approach is significantly faster and has a smaller memory
footprint. Trade-offs between the branch-and-bound and mip approaches are discussed
as well.
\end{abstract}

\newpage
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SECTION 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
Analyses of data are often hindered by occurrences of incomplete or
inconsistent raw data records.  The process of locating and correcting such
errors is referred to as {\em data editing}, and it has been estimated that
National Statistics Institutes may spend up to 40\% of their resources on this
process \citep{waal:2011}. Moreover, data are often required to obey many
cross-variable consistency rules which significantly complicate the data
editing process. Indeed, \citet{winkler:1999} mentions practical cases
(household surveys) where records have to obey 250, 300 or even 750
user-defined interrelated consistency rules.  For these reasons, considerable
attention is paid to the development of data editing methods that can be
automated. 

\subsection{Error localization}
Automated (and even manual) data editing strategies typically consist of three steps:
\begin{enumerate}
\item Find out which rules (expectations) a record violates;
\item find out which fields in a record cause those violations;
\item replace the values in those fields with better estimates, such that no rules
are violated anymore.
\end{enumerate}
The second step is usually referred to as the \emph{error localization}
problem, which is the focus of the current paper.  Although it is widely
recognized that data editing is a necessary step in the statistical process,
the amount of changes made to the data should obviously be minimized to avoid
introducing bias in estimations based on the edited data. This then, led to the
development of the following minimisation problem.
%
\begin{quote}
Given a record of $n$ variables, subject to a number of possibly multivariate
consistency rules. Find the smallest (weighted) subset of fields, such that their
original values can be replaced in such a way that no rules are violated anymore. 
\end{quote}
%
This minimization problem is named after \cite{fellegi:1976}, who first
formulated and solved the problem for the case of categorical data. Error
localization has been extensively discussed in literature\footnote{See
\citet{waal:2011} and references therein}, so we will suffice with a few
remarks. First, note that the minimization problem is possibly over a search
space of size $2^n$, rendering a brute-force approach that runs through all
possible solution candidates computationally infeasible. Second, the problem is
complicated by the occurrence of \emph{implied rules}. That is, the solution
set must not only allow the record to obey the original, user-defined set of
rules, but also rules that are logically or arithmetically implied by the
original set. To cope with these complications, several algorithmic approaches
have been developed, of which two are worth mentioning in this context:
the first is the branch-and-bound approach, developed by \cite{waal:2003a}.
The second is an approach based on mixed-integer programming (mip), described
in \cite{waal:2011}.

\subsection{The \code{editrules} package}
Over the past five to ten years, the \R{} statistical environment received a
surge in popularity and as a consequence it has been extended with many
packages that allow for statistical analyses of data. However, the number of
packages specifically aimed at data editing seems to be somewhat limited,
except possibly in the area of imputation.  The {\sf R} package {\sf editrules}
\citep{jonge:2011a} was developed to help to bridge the gap between raw data
retrieval and data analysis with {\sf R}.  The main purpose of the package is
to provide an easy and consistent interface to define data consistency rules
(often referred to as \emph{edit rules}) in \R{} and to confront them with
data. Furthermore, the package allows for basic rule manipulation (deriving new
rules, finding inconsistencies, \emph{etc.}) and for error localization
functionality.  in records.  As such, the package does not offer functionality
to correct data.  Rather, it is aimed at identifying the set of solutions to an
error correction problem: the first two steps mentioned in the data editing
strategy above. Previous developments of the package have been described
in \cite{jonge:2011,loo:2011b} and \cite{loo:2011a}.


The \code{editrules} package offers a fairly complete toolbox, allowing users
to work with numerical, categorical or mixed-type data editing rules. Up until
now, error localization was performed by an implementation of the
branch-and-bound algorithm described by \cite{waal:2003}. The main disadvantage
of this approach is that the branch-and-bound algorithm has $\mathcal{O}(2^n)$
worst-case time and memory complexity, where $n$ is the number of variables
occurring in a connected set of rules. Moreover, the branch-and-bound solver is
written in pure \R{}, making it intrisically slower than a compiled language
implementation. The main advantages of this approach are the ease of
implementation and the opportunity for users to exert fine-grained control over
the algorithm.

As stated before, the error localisation problem can, under mild conditions, be
translated to a mixed-integer programming problem, which offers the oppertunity
to reuse well-established results from the field of linear and mixed-integer
programming. Indeed, many advanced algorithms for solving such problems have
been developed and in many cases implementations in a compiled language are
available under a permissive license. In \code{editrules}, the solver of the
\code{lpsolve} library \citep{berkelaar:2004} is used through \R{}'s
\code{lpSolveAPI} package \citep{lpSolveAPI:2011}. The \code{lpsolve} library
is written in \code{ANSI} \code{C} and has been tried and tested extensively.

The strategy to solve error localisation problems through this library from 
\R{} therefore consists of translating the problem to a suitable mixed-integer
programming problem, feeding this problem to \code{lpSolveAPI} and retranslating
the results to an error location. 


For reasons to become apparent below, we distinguish between
\begin{itemize}
\item linear, numerical restrictions of the form $\mathbf{a}\cdot\mathbf{x}\leq b$;
\item restrictions on categorical data, of the form $\textrm{\textbf{if} } \mathbf{v} \in \mathbf{F} \textrm{\textbf{ then} FALSE}$;
\item restrictions on mixed-type data, for example $\textrm{\textbf{if} } x > 0 \textrm{ \textbf{then} } \mathbf{v} \in \mathbf{F} $.
\end{itemize}
Here, $\mathbf{x}$ is a vector of numerical variables and $\mathbf{a}$ and $b$ are
constants, $\mathbf{v}$ is a vector of categorical variables and $\mathbf{F}$ a vector of
subdomains for the elements of $\mathbf{v}$. The rules and their notations will be specified
in more detail in the sections to follow. 

The main part of this paper will focus on how to translate these types of error
localisation problems to a mixed-integer formulation, paying attention to both
theoretical and practical details.  We will give examples of how users can
apply this functionality to their own problemd  in \R{} and benchmark the new
mip-functionality against the existing branch-and-bound solution.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SECTION 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Error localization and mixed integer programming}
\label{sec:mipproblem}
%
A mixed integer programming problem is an optimisation problem that can be
written in the form
\begin{equation}
\begin{array}{r}
\textrm{Minimize } \mathbf{c}^T\mathbf{z}; \\
\textrm{s.t. }\mathbf{Rz} \leq \mathbf{d},
\label{eq:mipmin}
\end{array}
\end{equation}
%
where $\mathbf{c}$ is a constant vector and $\mathbf{z}$ is a vector consisting
of real and integer coefficients. The inner product $\mathbf{c}^T\mathbf{z}$ is
referred to as the \emph{objective function}.  Furthermore, $\mathbf{R}$ is a
coefficent matrix and $\mathbf{d}$ a vector of upper bounds. Formally, the
elements of \mathbf{c}, \mathbf{R} and \mathbf{d} are limited to the rational
numbers \citep{schrijver:1998}, which is never a problem in practice since we
are always working with a computer representation of numbers. 




The name \emph{mixed-integer programming} stems from the fact that $\mathbf{z}$
contains continuous as well as integer variables. When $\mathbf{z}$ consists
solely of continuous or integer variables, Problem~\eqref{eq:mipmin} reduces
respectively to a \emph{linear} or an \emph{integer programming} problem.  An
important special case occurs when the integer coefficients of \mathbf{z} may
only take values from \{0,1\}. Such variables are often called binary variables
or decision variables. It occurs as a special case since defining \mathbf{z} to
be integer and applying the appropriate restrictions yields the same problem.
Mixed integer programming is well understood and there several software
packages packages are available that implement efficient solvers.  Most mip
software allows for a broader (but equivalent) formulation of the mip problem,
allowing the set of restrictions to include inequalities as well as
equalities. As a side note, we mention that under equality constraints,
solutions for the integer part of $\mathbf{z}$ only exist when the equality
constraints pertaining to the integer part of \mathbf{z} are \emph{totally
unimodular}\footnote{This means that every square submatrix of the coefficient
matrix pertaining to the integer part of \mathbf{z} has determinant 0 or
$\pm1$.}. However, as we will see below, constraints that pertain to the real
and/or integer part of \mathbf{z} are always inequalities in our case, so this
is of no particular concern to us.


In this paper we reformulate Felligi Holt error localization
\citep{fellegi:1976} for numerical, categorical and mixed constraints in terms
of mip problems.  The precise reformulations of the error localization problem
for the three types of rules are different, but in each case the objective
function is of the form 
%
\begin{equation}
\mathbf{w}^T\mathbf{\Delta},
\end{equation}
where \mathbf{w} is a vector of positive weights and \mathbf{\Delta} a vector
of binary variables, one for each variable in the original record, that
indicates whether its value should be adapted. More precisely,
for a record $\mathbf{r}=(r_1,r_2,\ldots,r_n)$ of $n$ variables, we have
\begin{equation}
\Delta_i =\left\{\begin{array}{l}
1 \textrm{ if the value of }r_i\textrm{ must be adapted}\\
0 \textrm{ otherwise}.
\end{array}\right.
\label{eq:defineDelta}
\end{equation}
%
This objective function obviously  meets the requirement that the minimal
(weighted) number of variables should be adapted. 

For an error localisation problem, the restrictions of Problem
\eqref{eq:mipmin} consist of two parts, which we denote
\begin{equation}
\left[\begin{array}{c}
  \mathbf{R}^H\\
  \mathbf{R}^0
\end{array}\right] \mathbf{z} \leq 
\left[\begin{array}{c}
  \mathbf{d}^H\\
  \mathbf{d}^0
\end{array}\right]
\label{eq:errlocasmip}
\end{equation}
Here, the restrictions indicated with $H$ represent a matrix representation of
the user-defined (hard) restrictions that the original record $\mathbf{r}$ must
obey. The vector $\mathbf{z}$ is a numerical vector, containing at least a
numerical representation of the values in a record and the binary variables
\mathbf{\Delta}. An algorithmic mip-solver will iteratively alter the values of
\mathbf{z} until a solution satisfying \eqref{eq:errlocasmip} is reached. To make
sure that the objective function reflects the (weighted) number of variables
altered in the process, the restrictions in $\mathbf{R}^0$ serve to make sure that
the values in \mathbf{z} that represent values in \mathbf{r} cannot be altered
without setting the corresponding value in \mathbf{\Delta} to 1.

Summarizing, in order to translate the error localisation problem for the cases
of linear, categorical or conditional mixed restrictions to a mixed integer
problem, we need to properly define \mathbf{z}, the restriction set
$\mathbf{R}^H\mathbf{z}\leq \mathbf{d}^H$ and the restriction set
$\mathbf{R}^0\mathbf{z}\leq \mathbf{d}^0$.



%\subsection{Further reading}
%An overview of several mixed integer formulations for error localization can 
%be found in \citep{waal:2011} p. 75.
%Mixed integer programming (convex programming etc.).
%List of mip software.
%Internally the package \cite{lpSolveAPI:2011} is used to 
%solve the resulting mixed integer program.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SECTION 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Linear edit rules}
\label{sec:numdataerror}
For a numercical record \mathbf{x} taking values in $\mathbb{R}^n$, a set of linear
restrictions can be written as
\begin{equation}
\label{eq:linedits}
\mathbf{Ax}\leq \mathbf{b},
\end{equation}
where in \code{editrules}, we allow the set of restrictions to contain equalities,
inequalities ($\leq$) and strict inequalities ($<$). 
The formulation of these edit rules is very close to the formulation of the original
mip problem of Eq.\ \eqref{eq:mipmin}.

\subsection{Mip formulation}
\label{sec:linedits:mip}
The vector to miminize over is defined as follows:
\begin{equation}
\mathbf{z} = (x_1,x_2,\ldots,x_n,\Delta_1,\Delta_2,\ldots,\Delta_n).
\end{equation}
with the $\Delta_i$ as in Eq.\ \eqref{eq:defineDelta}. The set of restrictions
$\mathbf{R}^H\mathbf{z}\leq \mathbf{d}^H$ is equal to the set of restrictions
of Eqn.\ \eqref{eq:linedits}, except in the case of strict inequalities. The
reason is that while \code{editrules} allows the user to define strict
inequalities ($<$), the \code{lpsolve} library used by \code{editrules} only allows
for inclusive inequalities ($\leq$). For this reason, strict inequalities of the
form $\mathbf{a}^T\mathbf{x}<b$ are rewritten as $\mathbf{a}^T\mathbf{x}\leq
b-\epsilon$, with $\epsilon$ a suitably small constant.

In the case of linear edits, the set of constraints $\mathbf{R}^0\mathbf{z}\leq\mathbf{d}^0$
consists of pairs of the form
\begin{eqnarray*}
x_i - M\Delta_i   &\leq& x_i^0\\
-x_i - M\Delta_i  &\leq& -x^0_i,
\end{eqnarray*}
for $i=1,2,\ldots,n$. Here The $x^0_i$ are the actual observed values in the
record and $M$ is a suitably large constant allowing $x_i$ to vary between
$x_i^0-M$ and $x_i^0+M$.  It is not difficult to see that if $x_i$ is different
from $x_i^0$, $\Delta_i$ must equal 1. For, if we choose $x_i=x_i^0+\delta$ and
$\Delta_i=0$ we obtain the set of restrictions
\begin{eqnarray*}
\delta  &\leq& 0 \\
-\delta &\leq& 0,
\end{eqnarray*}
which is infeasible except when $\delta=0$.

This completes the formulation of the error localisation in the case of linear
edits in terms of a mip problem. The formulation comes at a cost of introducing
two more or less arbitrary numerical constants: $\epsilon$ and $M$. The
ramifications of this will be discussed in Section \ref{sec:linedits:num}
below. 

\subsection{Implementation and numerical subtleties}
\marginpar{\code{as.mip} wordt nergens gebruikt en is ook voor de gebruiker niet
nuttig: weglaten lijkt me.}
In {\sf editrules} an {\sf editmatrix} object is used to store linear 
constraints. This object is described extensively in {\cite{jonge:2011}},
and it can be generated (amongst other methods) by calling a function of the
same name. For example:
<<nummatrix example>>=
E <- editmatrix("y > x")
as.character(E)
@
%
The function \code{as.mip} translates the user defined restrictions in \code{E}
by adding `epsilons' where necessary:
<<>>=
as.mip(E)
@
The resulting object is an object of class \code{mip}. By default, a value of
$\epsilon=10^{-3}$ is chosen. However, this value may be controlled by passing
an extra \code{epsilon} argument. Without the values of an actual record, the mip
problem cannot be completed. Adding a record and (optionally) weights allows
\code{as.mip} to complete the mip formulation.
<<>>=
as.mip(E, x=c(x=10, y=0), weight=c(x=1,y=2))
@
The weights are incorporated in the objective function and the default value of $M$ equals
$10^7$. The value of $M$ can be user-controlled by passing the optional argument
\code{M}.


\subsection{Numerical subtleties}
\label{sec:linedits:num}
The mip formulation for numerical constraints depends on two constants $M$ and
$\epsilon$. These constants end up in the coefficient matrix of the mip solver.
Mathematically the size of these coefficients does not matter. Computationally 
however it does: if coefficient $a_{ij} \ll a_{kl}$ then the solution
may become numerical unstable, since the ratio of the two is 
indistinguishable from zero to the mip solver. 

In {\sf editrules} by default $M = 10^7$ and $\epsilon = 10^{-3}$ is used. This 
will 
be sufficient for most purposes, since numerical values and coefficients of the
constraints 
in most cases will be in this range. If not, you should rescale some of your
variables and constraints to make it so.

The linear programming manual from \code{lpsolve}  \citep{lpsolveman:2012} says the 
following on this matter:

\begin{quote}
The chance for numerical instability and rounding errors is considerably 
larger when the input data contains both large and small numbers. 
So to improve stability, one must try to work with numbers that are somewhat 
in the same range. Ideally in the neighborhood of 1.\\

You should realize, that you the user are probably in a better position to 
scale the problem than any computer algorithm. 
\end{quote}

\section{Categorical data errors}


\label{sec:catdataerror}
A categorical record $\bf v$  with reported values $({v^0_1,\dots,v^0_m)}$ has 
the following $n$ constraints:
\begin{equation}e_j = 
  \begin{array}{rl}
    \label{eq:catedit}
    \mbox{{\bf if }} & v_i \in F_{i,j} \mbox{ for }i = 1, \ldots, m \\
    \mbox{ {\bf then}} & \mbox{FALSE}
  \end{array}
\end{equation}
with $F_{i,j} \subseteq D_i$ where $i$ is the number of variables, $D_i$ is the
possible set of categories $\{c_{i,1}, \ldots, c_{i,l_i}\}$ for $v_i$ and $j = 1 \ldots n$ the number of edits.

Remarkable about categorical edits is their negative formulation in 
literature (e.g. \ref{}): if a condition is true than the edit is violated. 
This is in contrast with numerical edits, which state rules that the record
must obey. To translate categorical edits into mip we need a possitive 
reformulation, since mip requires constraints 
that must hold.

Equation (\ref{eq:catedit}) can be written in the following form:
\begin{eqnarray}
     e_j  & = & \lnot \bigwedge_{i=1}^m v_i \in F_{i,j} = \bigvee_{i=1}^m\lnot (v_i \in {F_{i,j}}) \\
          & = &  \bigvee_{i=1}^m v_i \not\in {F_{i,j}} = \bigvee_{i=1}^m v_i 
          \in T_{i,j} \label{eq:catpos}
\end{eqnarray}
with $T_{i,j} = D_i \setminus F_{i,j}$. 
This means that edit $e_j$ is satisfied if at least one $v_i \in T_{i,j}$. 

\subsection{Mip formulation}
\begin{itemize}
  \item[a)]
  Recall from section \ref{sec:mipproblem} that in a mip problem ${\bf x}$ is a 
  numerical vector. We therefore encode each categorical variable $v_i$ in $l_i$
  binary dummy variables
  $$
  v_i = (d_{i,1}, \ldots, d_{i,l_i})
  $$
  with
  \begin{equation}
    d_{i,k} = \left\{ 
    \begin{array}{ll}
           1 & \mbox{if $v_i = c_{i,k}$}\\
           0 & \mbox{if $v_i \neq c_{i,k}$}
    \end{array} \right. 
  \end{equation}
  
  The numerical representation of $\bf{v}$, a record of $m$ categorical variables 
  can then be written as:
  \begin{equation}
    {\bf x} = (d_{1,1}\ldots d_{1,l_1}, \ldots, d_{m, 1}, \ldots, d_{m, l_m}, 
    \Delta_1, \ldots, \Delta_m)
  \end{equation}
  
  \item[b)]
  Constraint matrix ${\bf A}^H$ for categorical edits is composed out of two parts.
  First the fact that each $v_i$ can only have one categorical value:
  \begin{equation}
     \sum^{n_i}_{k=1} d_{i,k} = 1
  \end{equation}
  for $i$ is $(1, \ldots, m)$
  
  Second the categorical constraints of equation \ref{eq:catpos}. 
  They can now be written as:
  
  \begin{equation} \label{eq:mipcatedit}
    \sum^m_{i=1} \left(\sum^{l_i}_{k=1} t_{i,j,k} \cdot d_{i,k}\right) 
    \geq 1
  \end{equation}
  
  \begin{equation} \label{eq:aijk}
    \mbox{with }
    t_{i,j,k} = \left\{ 
    \begin{array}{ll}
           0 & \mbox{if } c_{i,k} \not\in T_{i,j}\\
           1 & \mbox{if } c_{i,k} \in T_{i,j}
    \end{array} \right. 
  \end{equation}
  Meaning that if one of the $c_{i,k} \in T^j_i$ then the edit is valid.\\
  
  
  \item[c)]
  The constraints ${\bf A}^0$ can be written as:
  
  \begin{equation}
     d_{i,k^0_i}  =  1 - \Delta_i 
  \end{equation}
  where $k^0_i$ denotes the reported value $v^0_i$.
  It can be easily checked that if $\Delta_i = 0$ $d_{i,k^0} = 1$, 
  meaning that the reported value 
  $v^0_i$ is assumed correct. 
  If $\Delta_i = 1$, $d_{i,k^0_i} = 0$, meaning that $v_i$ must have a different 
  value. Since mip minimizes the objective function it will try to keep the reported 
  values at $v^0_i$.
\end{itemize}
This makes the mip formulation for categorical edits complete.

\subsection{Implementation}
\code{editrules} uses \code{editarray} for dealing with categorical edits. These
are described in \cite{loo:2011b}. An example \code{editarray} is given below.
<<tidy=FALSE>>=
(E <- editarray(expression(
    gender %in% c('male','female'),
    pregnant %in% c(TRUE, FALSE),
    if (pregnant) gender == 'female'
    )
))
@
\code{E} is an editarray. That \code{E} parses the constraints can be seen in 
the pregnant constraint: it has been rewritten in an equivalent form.
To create a mip formulation for the categorical error localization problem,
\code{editrules} rewrites categorical edits into a numerical matrix using the
function \code{as.mip}.
<<>>=
as.mip(E)
@
Above example shows the rewriting of ${\bf A}^H$. All variables are binary 
variables $\in \{0,1\}$. Constraint \code{num1} states
that \code{gender} either must be \code{'male'} or \code{'female'}. Constraint 
\code{num2} states that \code{pregnant} and \code{gender:male} cannot both be
1 (true).

Note that \code{as.mip} 
recognizes that \code{pregnant} is a \code{logical}. The mip formulation contains
just one binary variable for \code{pregnant}.
(explain...)

If we add the $A^0$
constraints we get:
<<tidy=FALSE>>=
as.mip( E
      , x=list(gender="male", pregnant=TRUE)
      , weight=c(1,2)
      )
@
(explain)
\section{Mixed data errors}
\label{sec:mixdataerror}

Often a data set or survey contains both numerical as categorical variables.
In that case there are often hard constraints including both types
of variables. Such a constraint is called a mixed edit or mixed constraint.
{\sf editrules} allows for mixed constraints which are extensively described in 
\ref{}.

The branch and bound implementation of {\sf editrules} works, but is inefficient
for larger problems. It very quickly generates large memory objects and 
takes a long time to finish. For these problems a {\sf mip} implementation comes
to the rescue.

A set of mixed constraints contains pure numerical, pure categorical
and mixed constraints. 

A mixed record $\bf r$  with reported values $({r^0_1, \dots,r^0_l,
v^0_1,\dots,v^0_m)}$ has the 
following $n$ constraints:
\begin{equation}e_j = 
  \begin{array}{rl}
    \label{eq:mixedit}
    \mbox{{\bf if }} & v_i \in F_{i,j} \mbox{ for }i = 1, \ldots, m \\
    \mbox{ {\bf then}} & \sum^l_{k=1} a_{jk} \cdot r_k \leq b_j \\ 
  \end{array}
\end{equation}
with $F_{i,j} \subseteq D_i$ where $i$ is the number of variables, $D_i$ is the 
possible set of categories $\{c_{i,1}, \ldots, c_{i,l_i}\}$ for $v_i$ and 
$j = 1 \ldots n$ the number of edits.

Equation \ref{eq:mixedit} can written in a more general form:

\begin{equation}
e_j = \bigvee_{i=1}^m (v_i \in T_{i,j}) \vee \sum^l_{k=1} a_{jk} \cdot r_k 
\odot b_j
\end{equation}

\subsection{Mip formulation}
\begin{itemize}
  \item[a]
  
  The numerical representation of $\bf{x}$, a record of $k$ numerical variables
  and $m$ categorical variables can then be written as:
  \begin{equation}
    {\bf x} = (r_1, \ldots, r_k, 
              d_{1,1}\ldots d_{1,l_1}, \ldots, d_{m, 1}, \ldots, d_{m, l_m},
              \Delta_1, \ldots, \Delta_{k+m}, n_1, \ldots, n_p)
  \end{equation}
  with
  \begin{equation}
    n_j = \left\{ 
    \begin{array}{ll}
           0 & \mbox{if $\sum^l_{k=1} a_{jk} \cdot r_k \leq b_j$}\\
           1 & \mbox{if $\sum^l_{k=1} a_{jk} \cdot r_k \not \leq b_j$}
    \end{array} \right. 
  \end{equation}

  It is the union of the numerical and categorical description plus extra binary 
  variables $n_i$. Each $n_i$ is a dummy variable introduced to represent a 
  negated numerical constraint which is part of a mixed edit.
  
  \item[b]
  The constraints ${\bf A}^H$ are a combination of the categorical and numerical 
  descriptions. For purely numerical and categorical constraints we use the 
  formulations as stated in previous sections.
  
  A mixed constraint is formulated in (at least) two parts: a categorical part and
  numerical parts.
  First equation \ref{eq:mipcatedit} is extended with 
  numerical dummy 
  variable $n_j$. For each mixed edit we add the following constraint to ${\bf A}^H$
  \begin{equation}
    \label{eq:mixcatedit}
    \sum^m_{i=1} \left(\sum^{l_i}_{k=1} t_{i,j,k} \cdot d_{i,k}\right) + (1-n_j)
    \geq 1
  \end{equation}
  meaning that one of the categorical or numerical conditions must hold.
  
  Further more for each $n_j$ we add the following constraint
  \begin{equation}
    \label{eq:mixnumedit}
    \sum a_{jk} \cdot r_k \leq b_j + Mn_j
  \end{equation}
  With $M$ a sufficiently large number.
  
  
  This means that if $n_j = 0$ the numerical constraint must hold and the
  constraint of eq. \ref{eq:mixcatedit} always holds. If $n_j=1$ then the 
  numerical constraint is not enforced, since $M$ makes the constraint of
  eq. \ref{eq:mixnumedit} always true.
  
  \item[c]
  Constraints ${\bf A}^0$ for a mixed record $r$ are simply the 
  union of the numerical ${\bf A}^0$ for ${\bf r}^0$ and the categorical ${\bf A}^0$ 
  for ${\bf v}^0$.
  
\end{itemize}

This makes the mip formulation for mixed constraints complete.

\subsection{Implementation}

<<tidy=FALSE>>=
E <- editset(expression(
  married %in% c(TRUE, FALSE),
  if (married==TRUE) age >= 17
  ))
@

Writing this to ${\bf A}^H$ form we get:
<<>>=
as.mip(E)
@
(explain...)

Adding some (inconsistent!) ${\bf A}^0$ we get:
<<>>=
as.mip(E, x=list(age=9, married=TRUE))
@
(explain...)

\section{Usage}
The mip implementation in \code{editrules} is transparent.
The \code{localizeErrors} function is extended to include an extra parameter
\code{method}. The default value of \code{method} is \code{'bb'}: branch and bound.
Setting \code{method} to \code{'mip'} gives identical but faster result.

<<num example>>=
E <- editmatrix("x <= y")
dat <- data.frame(x=c(10, 2), y=c(1,2))
weight <- data.frame(x=c(2,1), y=c(1,1))

bb <- localizeErrors(E, dat, weight=weight)
mip <- localizeErrors(E, dat, weight=weight, method="mip")

bb$adapt
mip$adapt
@

Internally {\sf localizeErrors} uses for each record {\sf errorLocalizer.mip}.
Unlike {\em branch and bound} this is not a \code{backtracker} object.
\code{errorlocalizer.mip} writes the constraints and values into a mip problems,
feeds it into the \code{lpSolveApi} and formats the resulting output.
<<num mip>>=
E <- editmatrix("x <= y")
r <- c(x=10, y=1)
weight <- c(x=2, y=1)
el <- editrules:::errorLocalizer.mip(E, r, weight=weight)
ls.str(el)
@
Both \code{localizerErrors} as \code{errorLocalizer.mip} can be executed with a 
\code{editmatrix}, \code{editarray} or \code{editset} object.

Note in the example that the {\em mip} solver returns two extra properties that are
not available in {\em branch and bound}: \code{lp} and \code{x\_feasible}.
Since a mip-solvers goal is to find a feasible solution, a set of feasible x 
values is available. It can be helpful to have these values, but note 
that the set is not unique and that the proposed values for the variables to be 
adjusted lie on the boundary of a convex solution region. 
So  in many cases it is better to use proper imputation method to generate
sensible values for the variable that need to be adjusted.
Secondly \code{errorlocalizer.mip} returns the \code{lp} object. This object is 
a \code{lpSolveApi} object and can be further manipulated or written to disk.
For more information consult the manual of \code{lpSolveApi}.

A advantage of the branch and bound algorithm is that it can generate all optimal
solutions for a given record.  The mip implementation only generates one of the 
best. This is implemented by adding a small uniform pertubation to the weights, 
so mip chooses one of the best at random. This is identical 
to the default behavior of \code{localizeErrors} for \code{method='bb'}.

\section{Conclusion}
\code{editrules} includes a mip implementation of the localize errors formalism 
of Felligi and Holt. This mip implementation is typically must faster than the
branch and bound algorithm. 

For most problems mip will generate a good solution. However for problems where
coefficients or values exceed the range of $[10^{-3} - 10^7]$ the user has to rescale
the problem: otherwise the mip solver will become unstable.

\bibliographystyle{chicago}
\bibliography{editrules}

\end{document}

