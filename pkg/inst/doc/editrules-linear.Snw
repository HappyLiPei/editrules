%\VignetteIndexEntry{Linear edit manipulation and error localization with the editrules package}
\documentclass[10pt, fleqn, a4paper]{article}
\usepackage[english]{babel}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{threeparttable}
\usepackage{natbib}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage{threeparttable}
\DeclareMathOperator*{\argmin}{\arg\!\min}

\usepackage{float}
 
\floatstyle{boxed}
\newfloat{Rcode}{t}{rco}
\floatname{Rcode}{Figure}
 


% stimulate latex to put multiple floats on a page.
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{3}
\setcounter{dbltopnumber}{2}
\renewcommand{\topfraction}{.9}
\renewcommand{\textfraction}{.1}
\renewcommand{\bottomfraction}{.75}
\renewcommand{\floatpagefraction}{.9}
\renewcommand{\dblfloatpagefraction}{.9}
\renewcommand{\dbltopfraction}{.9}
\hyphenation{time-stamp}


\title{Linear edit manipulation and error localization with the {\tt editrules} package}
\author{Edwin de Jonge and Mark van der Loo}
\begin{document}
\maketitle
\begin{abstract}
{\em This vignette is far from finished. Version 1.0 fo the package will have
the full vignette.}
This paper is the first of two papers describing the editrules package. The current paper
is concerned with numerical data under linear constraints, while the accompanying paper
is concerned with constrained categorical and mixed data.
\end{abstract}

<<echo=FALSE, keep.source=FALSE>>=
library(editrules)
@
\maketitle

\tableofcontents
\newpage

\section{Introduction}
The value domain of real numerical data records with $n$ variables is often restricted
to a subdomain of $\mathbb{R}^n$ due to linear equality and inequality relations
which the variables in the record have to obey. Examples include equality restrictions imposed
by financial balance accounts, positivity demands on certain variables or limits on the
ratio of variables.

Any such restriction is of the form
\begin{equation}
\label{edit}
{\bf a}\cdot{\bf x} \odot b\textrm{ with }\odot\in\{<,\leq,=\},
\end{equation}
where $\bf x$ is a numerical data record, ${\bf a}$, ${\bf x}\in \mathbb{R}^n$
and $b\in \mathbb{R}$. In data editing literature, data restriction rules
are refered to as {\em edits}, or {\em edit rules}. We will call edits, written
in the form of Eq.\ \eqref{edit}, edits in {\em normal form}. 

Large complex surveys are often endowed with dozens or even hundreds of edit
rules.  For example, the Dutch Structural Business Survey, which aims to report
on the financial structure of companies in the Netherlands, contains on the
order of 100 variables, endowed with a similar number of linear equality and
inequality restrictions.

Defining and manipulating large edit sets can be a daunting task when
implemented directly as matrix representations. Also, edit violations give
rise to the error localization problem, which can quite simply be stated as
{\em which variables contain the errors that cause a record to violate certain
edits rules?}.

The {\tt editrules} package for the R statistical computing environment
\citep{R-core:2011} aims to provide an environment to conveniently define,
parse and check linear (in)equality restrictions, perform common edit
manipulations and offer error localization functionality based on the
(generalized) paradigm of \cite{fellegi:1976}. This paradigm is based on the
assumption that errors are distributed randomly over the variables, and there
is no detectable cause of error. The paradigm also decouples the detection from
correction of corrupt variables. Certain causes of error, such as sign flips,
typing errors or rounding errors can be detected and are closely related to
their resolution. The reader is referred to the {\tt deducorrect} package
\citep{loo:2011, scholtus:2008, scholtus:2009} for treating such errors. 

The following chapters demonstrates the functionality of the {\tt editrules}
package with coded examples as well a description of of the underlying theory and
algorithms. For a detailed per-function description the reader is referred to
the reference manual accompanying the package. Unless mentioned otherwise,
all code shown in this paper can be executed from the R commandline after loading
the {\tt editrules} package.


\section{Defining and checking numerical restrictions}

\subsection{The {\tt editmatrix} object}
For computational processing, a set of edits of the form 
\begin{equation}
{\bf a}\cdot{\bf x} \odot b\textrm{ with }\odot\in\{<,\leq,=,\geq,>\}.
\label{nonnormaledit}
\end{equation}
is most conveniently represented as a matrix.  In the {\tt editrules} package,
a set of linear edits is stored as an {\tt editmatrix} object.  This 
object stores the linear relations as an augmented matrix $[{\bf
A},{\bf b}]$, where $\bf A$ is the matrix obtained by combining the  ${\bf a}$
vecors of Eq.\ \eqref{nonnormaledit} in rows of $\bf A$ and constants  $b$ in $\bf b$. A
second attribute holds the comparison operators as a {\tt character} vector.
Formally, we denote that every {\tt editmatrix} $E$ is defined by
\begin{equation}
E = \left\langle [\mathbf{A},\mathbf{b}],\boldsymbol{\odot}\right\rangle 
\textrm{ with } [{\bf A},{\bf b}]\in \mathbb{R}^{m\times{n+1}},\:
\boldsymbol{\odot}\in\{<,\leq,=,\geq,>\}^{m},
\label{editset}
\end{equation}
where $n$ is the number of variables, $m$ the number of edit rules and the
notation $\langle \:,\:\rangle$ denotes a combination of objects.  Retrieval
functions for various parts of an {\tt editmatrix} are available, see Table
\ref{simplemanipulations} (p.\ \pageref{simplemanipulations}) for an overview.
Defining augmented matrices by hand is tedious and prone to error, which is why
the {\tt editmatrix} function  derives edit matrices from a textual
representation of edit rules. Since most functions of the {\tt editrules}
package expect an {\tt editmatrix} in normal form (that is
$\boldsymbol{\odot}\in\{<,\leq,=\}$), the {\tt editmatrix} function by default
transforms all linear edits to normal form.

As an example, consider the set of variables
\begin{center}
\begin{tabular}{ll}
turnover       & $t$ \\
personell cost & $c_p$\\
housing cost   & $c_h$\\
total cost     & $c_t$\\
profit         & $p$, \\
\end{tabular}
\end{center}
subject to the rules
\begin{eqnarray}
\label{e1}
t   &=& c_t + p\\
c_t &=& c_h + c_p\\ 
p &\leq& 0.6t\\
c_t &\leq& 0.3t\\
c_p&\leq& 0.3t\\
t   &>& 0\\
c_h &>& 0\\
c_p &>& 0\\
\label{e9}
c_t &>& 0.
\end{eqnarray}
Clearly, these can be written in the form of Eq.\ \eqref{edit}.  Here, the
equality restrictions correspond to balance accounts, the 3rd, 4th and 5th
restrictions are sanity checks and the last four edits demand positivity.  
Figure \ref{emfromtext} shows how these edit rules can be
transformed from a textual representation to a matrix representation with the
{\tt editmatrix} function.
%
\begin{Rcode}
<<keep.source=true>>=
E <- editmatrix(c(
"t  == ct + p" ,
"ct == ch + cp",
"p  <= 0.6*t",
"cp <= 0.3*t",
"ch <= 0.3*t",
"t  >  0",
"ch >  0",
"cp >  0",
"ct >  0"), normalize=TRUE)
E
@ 
\caption{Defining an {\tt editmatrix} from a {\tt character} vector containing verbose edit statements.
The option {\tt normalize=TRUE} ensures that all comparison operators are either ${\tt <}$, ${\tt \leq}$ or ${\tt ==}$.}
\label{emfromtext}
\end{Rcode}
%

As Figure \ref{emfromtext} shows, the {\tt editmatrix} object is shown on the console
as a matrix, as well as a set of textual edit rules. The {\tt editrules}
package is capable of coercing a set of R expressions to an {\tt editmatrix}
and {\em vice versa}. To coerce text to a matrix, the {\tt editmatrix} function
processes the R language parsetree of the textual R expressions as provided by
the R internal {\tt parse} function. To coerce the matrix representation to
textual representation, an R character string is derived from the matrix which
can be parsed to a language object.

In the example, the edits were automatically named {\tt e1}, {\tt e2}, $\ldots$, {\tt e9}. It is
possible to name and comment edits by reading them from a {\tt data.frame}. 

\begin{Rcode}[t]
<<keep.source=true>>=
# generate a csv text string
E.csv <- 
'name , edit       , description
"b1"  ,    t == ct + p    ,  "total balance"
"b2"  ,    ct == ch + cp  ,  "cost balance"
"s1"  ,    p <= 0.6*t     ,  "profit sanity"
"s2"  ,    cp <= 0.3*t    ,  "personell cost sanity"
"s3"  ,    ch <= 0.3*t    ,  "housing cost sanity"
"p1"  ,    t >0           ,  "turnover positivity"
"p2"  ,    ch > 0         ,  "housing cost positivity"
"p3"  ,    cp > 0         ,  "personel cost positivity"
"p4"  ,    ct > 0         ,  "total cost positivity"'
# read into a data.frame
E.df <- read.csv(textConnection(E.csv))
# transform to an editmatrix
editmatrix(E.df)
@
\caption{Declaring an editmatrix with a {\tt data.frame}. The input {\tt data.frame} is required to have three columns named
{\tt name},(edit name, stored as rowname of augmented matrix) {\tt edit} (textual representation of the edit rule) 
and {\tt description} (a comment stating the intent of the rule). All must be of type {\tt character}.}
\end{Rcode}
%

The ability to read edit sets from a {\tt data.frame} facilitates defining and
maintaining the rules outside of the R environment by storing them in a
user-filled database or textfile. Manipulating and combining edits, for example
through variable elimination methods will cause {\tt editrules} to drop or
change the names and drop the comments, as they become meaningless after
certain manipulations.

\subsection{Basic manipulations and edit checking}
Table \ref{simplemanipulations} shows simple manipulation functions available
for an {\tt editmatrix}. Basic manipulations include retrieval functions for
the augmented matrix, coefficient matrix, constant vector and operators of an
{\tt editmatrix}. There are functions to test for and transform to normality.
The function {\tt violatedEdits} expects an {\tt editmatrix} and a {\tt
data.frame} or a named numeric vector. It returns a {\tt logical} {\tt array}
where every row indicates which edits are violated ({\tt TRUE}) by records in
the {\tt data.frame}. Figure \ref{violatedEdits} demonstrates the result of
checking two records against the editrules defined in Eqs.\ \eqref{e1}--\eqref{e9}.
%
%
\begin{table}
\begin{threeparttable}
\caption{Simple manipulation functions for objects of class {\tt editmatrix}. Only the
mandatory arguments are shown, refer to the built-in documentation for optional arguments.}
\label{simplemanipulations}
\begin{tabular}{ll}
\hline
function                      & description\\
\hline
{\tt getA(E)}                 & Get matrix $\bf A$\\
{\tt getb(E)}                 & Get constant vector $\bf b$\\
{\tt getAb(E)}                & Get augmented matrix $[{\bf A},{\bf b}]$\\
{\tt getOps(E)}               & Get comparison operators\\
{\tt E[i,]}                   & Select edit(s) \\
{\tt as.editmatrix(A,b,ops)}  & Create an {\tt editmatrix} from its attributes\\
{\tt normalize(E)}            & Transform {\tt E} to normal form\\
{\tt isNormalized(E)}         & Check whether {\tt E} is in normal form\\
{\tt violatedEdits(E, x)}     & Check which edits are violated by ${\bf x}$\\
{\tt duplicated(E)}           & Check for duplicates in rows of {\tt E}\\
{\tt isObviouslyRedundant(E)} & Check for tautologies and duplicates in  {\tt E}\\
{\tt isObviouslyUnfeasible(E)}& Check for contradictions in rows of {\tt E}\\
{\tt isFeasible}              & Complete feasibility check for {\tt E}\\ 
\hline
\end{tabular}
\end{threeparttable}
\end{table}
%
%
\begin{Rcode}
<<keep.source=true>>=
# define two records in a data.frame
dat <- data.frame(
  t = c(1000, 1200),
 ct = c(400,  200),
 ch = c(100,  350),
 cp = c(500,  575),
 p =  c(500,  652 ))
# check for violated edits
violatedEdits(E,dat)
@
\caption{Checking which edits are violated for every record in a {\tt data.frame}.
The first record violates {\tt e1} and {\tt e2}, the second record violates {\tt e1},{\tt e2}, and {\tt e4}.}
\label{violatedEdits}
\end{Rcode}
%
%
Indexing of edits with the {\tt [} operator is restricted to selection only. 
No assignment can be made to indexed {\tt editmatrix} objects. In stead, 
{\tt as.editmatrix} should be used.

\subsection{Obvious redundancy and infeasibility}
When manipulating linear edit sets by value substitution and/or variable
elimination, the edit set can become polluted with redundant edits or, when
variable values are substituted, become infeasible. The {\tt editrules} 
package has two methods available which check for easily detectable
redundancies or infeasibility. The Fourier-Motzkin elimination method
has auxilary built-in redundancy removal, which is described in Section
\ref{sfouriermotzkin}.

A system of inequalities $\bf Ax\leq b$ is called infeasible when there is no
real vecor $\bf x$ satisfying it. It is a consequence of Farkas' lemma
(\cite{farkas:1902}, but see \cite{schrijver:1998} and/or \cite{kuhn:1956}) on
feasibility of sytems of linear equalities, that  a system is infeasible if and
only if $0\leq -1$ can be derived by taking positive linear combinations of the
rows of the augmented matrix $[{\bf A},{\bf b}]$. The function {\tt
isObiouslyinfeasible} returns a {\tt logical} indicating whether such a
contradiction is present. Subsitution of values may also lead to equalities of
the form $0=1$, which also indicate that the system has become infeasible.
Being obviously infeasible is sufficient for an {\tt editmatrix} to be
infeasible, but not necessary. Algorithm \ref{isObviouslyInfeasible} gives the
pseudocode for reference purposes.

The function {\tt isFeasible} eliminates variables one by one using
Fourier-Motzkin elimination (Section \ref{sfouriermotzkin}), and checks for obvious
infeasibilities. If no obvious inconsistencies are found after the last
variable has been eliminated, the system is consistent.
%
\begin{algorithm}[t]
\caption{{\sc isObviouslyInfeasible($E$)}}
\label{isObviouslyInfeasible}
\begin{algorithmic}
\Require a normalized {\tt editmatrix} $E$
\For {${\bf a}\cdot {\bf x}\odot b\in E$}
 \If{$\bf a=0$}
  \If {$(\odot\in\{=\}\land b\not=0)\lor(\odot\in\{\leq,<\}\land b<0)$} 
    \State \Return {\sc true}
  \EndIf
 \EndIf
\EndFor
\State\Return {\sc false}
\Ensure \Comment{{\tt logical} indicating if $E$ is obviously infeasible.}
\end{algorithmic}
\end{algorithm}
%
%
\begin{algorithm}[t]
\caption{{\sc isObviouslyRedundant}($E$, duplicates, $\varepsilon$)}
\label{isObviouslyRedundant}
\begin{algorithmic}
\Require a normalized {\tt editmatrix} $E$, with $m$ edits, a boolean ``duplicates'', and a tolerance $\varepsilon$.
\State  ${\bf v} \leftarrow$ ({\sc false})$^{\times{m}}$
\For {${\bf a}_i\cdot {\bf x}\odot b_i\in E$}
 \If{$\bf a=0$}
  \If {$(\odot\in\{=\}\land b=0)\lor(\odot\in\{\leq,<\}\land b>0)$} 
    \State $v_i\leftarrow${\sc true}
  \EndIf
 \EndIf
\EndFor
\If {duplicates}
\For {$\{({\bf a}_i\cdot {\bf x}\odot_i b_i,\,{\bf a}_j\cdot {\bf x}\odot_j b_j)   \in E\times E\,:\, j>i\}$ }
    \If {$|({\bf a}_i,b_i)-({\bf a}_j,b_j)|\leq \varepsilon$ elementwise $\land\: \odot_i=\odot_j$}
        \State $v_j\leftarrow${\sc true} 
    \EndIf  
\EndFor
\EndIf
\Ensure ${\bf v}$ \Comment{{\tt logical} vector indicating which rows of $E$ are obviously redundant.}
\end{algorithmic}
\end{algorithm}

When new edits are derived, either by value substitution or by variable
elimination, redundant rules of the form $0 \leq 1$ or $0=0$ can be generated.
The function {\tt isObviouslyRedundant} detects such rules and returns a {\tt
logical} vector indicating which rows of an {\tt editmatrix} are redundant.
By default, the function detects row duplicates (within an adjustable tolerance),
but this may be swithched of by providing the option {\tt duplicates=FALSE}.
Pseudocode is given in Algorithm \ref{isObviouslyRedundant}. The actual implementation
avoids explicit loops and makes use of R's built-in {\tt duplicated} function,
which is also overloaded for {\tt editmatrix} (see Table \ref{simplemanipulations}).






\section{Manipulation of linear restrictions}
There are two fundamental operations possible on edit sets, both of which
(possibly) reduce the number of variables involved in the edit set. The first,
most simple one is when a value is substituted into an edit. The second
possibility is variable elimination. For a set of linear equalities, one can
apply Gaussian elimination, while for sets of inequalities or mixed sets of
equalities and inequalities Fourier-Motzkin elimination is applied. While
variable substitution and Gaussian elimination guarantee that the eliminated
variable is not involved in the derived edit set anymore, this is not
necessarily the case for Fourier-Motzkin elimination.






\subsection{Value substitution}
Given a set of $m$ linear edits as defined in Eq.\ \eqref{editset}. For
any record $\bf x$ it must hold that
\begin{equation}
{\bf Ax}\boldsymbol{\odot}  {\bf b},\quad \boldsymbol{\odot}\in\{<,\leq,=,\geq,>\}^m.
\label{subst}
\end{equation}
Substituting one of the unknowns $x_j$ by a certain value $x$ amounts to
replacing the $j^{\rm th}$ column of $\bf A$ with ${\bf 0}$ and ${\bf b}$ with
${\bf b}-{\bf a}_j'x$. After this, the reduced record of unknowns, with $x_j$
replaced by $x$ has to obey the adapted system \eqref{subst}. For reference
purposes, Algorithm \ref{replaceValue} spells out the substitution routine.
The function was named {\tt replaceValue} since {\tt substitute} is already
defined in the R-base. Figure \ref{RreplaceValue} shows how {\tt replaceValue}
can be called from the R environment.
%
%
\begin{algorithm}[t]
\caption{{\sc replaceValue}$(E,j,x)$}
\label{replaceValue}
\begin{algorithmic}
\Require $E=\langle [{\bf A}=[{\bf a}_1,{\bf a}_2,\ldots,{\bf a}_j ,\ldots, {\bf a}_n]|{\bf b}],\boldsymbol{\odot}\rangle$, 
    $x\in\mathbb{R}$, $j\in \{1,2,\ldots n\}$
\State\Comment{Note that here, the subscripts of ${\bf a}$ denote the column index of {\bf A}}
\Ensure $\left\langle\left[{\bf A}=[{\bf a}_1,{\bf a}_2,\ldots,{\bf a}_{j-1},{\bf 0},{\bf a}_{j+1},\ldots {\bf a}_n\right]|
    {\bf b}-{\bf a}_jx],\boldsymbol{\odot}\right\rangle$
\end{algorithmic}
\end{algorithm}

\begin{Rcode}
<<>>=
replaceValue(E,"t",10)
@
\caption{Substituting the value 10 for the turnover variable using the {\tt replaceValue} function.}
\label{RreplaceValue}
\end{Rcode}


\subsection{Gaussian elimination}
The well-known Gaussian elimination routine has been implemented here as a
utility function, enabeling users to reduce the equality part of their edit
matrices to reduced row echelon form.  The {\tt echelon} function has been
overloaded to take either an R {\tt matrix} or an {\tt editmatrix} as argument.
In the latter case, the equalities are transformed to reduced row echelon form,
while inequalities are left untreated. Gaussian elimination is explained in
many textbooks. Algorithm \ref{echelon} is written in a notation which is close
to our R implementation in the sence that it involves just one explicit loop. 
Figure \ref{Rechelon} demonstrates a call to the R function.
%
%
\begin{algorithm}[t]
\caption{{\sc echelon($E$)}}
\label{echelon}
\begin{algorithmic}
\Require An {\tt editmatrix} of the form $\langle [{\bf A}|{\bf b}],=\rangle$, $[{\bf A|b}]\in \mathbb{R}^{m\times {n+1}}$, $m\leq n+1$.
\State $I\leftarrow \{1,2,\ldots,m\}$
\State $J\leftarrow \{1,2,\ldots,n+1\}$
\For {$j\in I$} \Comment{eliminate variables}
\State $i\leftarrow \arg\max_{i^\prime\,:\,j\leq i^\prime\leq m}|A_{i^\prime j}|$
\If {$|A_{ij}|>0$}
\If {$i > j$} 
\State Swap rows $i$ and $j$ of $[{\bf A|b}]$.
\EndIf
\State $[{\bf A|b}]_{I\backslash j,J}\leftarrow [{\bf A|b}]_{I\backslash j,J} - [{\bf A|b}]_{I\backslash j,j}\otimes [{\bf A|b}]_{j,J}A_{jj}^{-1}$ 
\EndIf
\EndFor
\State Divide each row $[{\bf A|b}]_{i,J}$ by $A_{ii}$ when $A_{ii}\not=0$
\State Move rows of $[{\bf A|b}]$ with all zeros to bottom.
\Ensure $E$, transformed to reduced row echelon form.
\end{algorithmic}
\end{algorithm}


\begin{Rcode}
\small
<<>>=
echelon(E)
@
\caption{Transforming linear equalities of an editmatrix to
reduced row echelon form. See Figure \ref{emfromtext} for the original definition of {\tt E}.}
\label{Rechelon}
\end{Rcode}



\subsection{Fourier-Motzkin elimination}
\label{sfouriermotzkin}
Fourier-Motzkin elimination [\cite{fourier:1826,motzkin:1936}, but see
\cite{williams:1986} for an elaborate or \cite{schrijver:1998} for a consice
description] is an extension of Gaussian elimination to solving systems of
linear inequalities. While Gaussian elimination is based on the reversible
operations of row permutation and linear combination, Fourier-Motzkin
elimination is based on the irreversible action of taking positive combinations
of rows.

A full Fourier-Motzkin operation on a system of inequalities involves
eliminating variables (where possible) one by one from the augmented matrix
$[{\bf A|b}]$. Eliminating a single variable is an important step in the error
localization algorithms elaborted in Section \ref{errorlocalization}. 

Consider a system of inequalities ${\bf Ax}\leq {\bf b}$.  The $j^{\rm th}$
variable  is eliminated by generating a positive combination of every row of
$[{\bf A|b}]$ where $A_{ij}>0$ with every row of $[{\bf A|b}]$ where $A_{ij}<0$
such that for the resulting row the $j^{\rm th}$ coefficient equals zero. Rows
of $[{\bf A|b}]$ for which $A_{ij}=0$ are copied to the resulting system. If
the system does not contain rows for which $A_{ij}>0$ and rows for which
$A_{ij}<0$, an elimination operation leaves the system unchanged. 

Mixed systems with linear restrictions of the form ${\bf a}\cdot {\bf x}\odot
b$ with $\odot\in\{<,\leq,=\}$ can in principle be transformed to a form where
every $\odot \in\{\leq\}$. However, it is more efficient to take the comparison
operators into account when combining rows. In that case, new rules are derived
by first solving the the $j^{\rm th}$ from each equality and substituting them in
each inequality. Next, inequalities are treated as stated before. When
inequalities are combined where one comparison operator is $<$ and the other is
$\leq$, it is not difficult to show that $<$ becomes the operator for the
resulting inequality.

It is a basic result of the theory of linear inequalities that the system
resulting from a single variable elimination is equivalent to the original
system (that is, they have the same solution set $\{\bf x\}$). In fact, $k$
elimination steps can generate up to $(\tfrac{1}{2}m)^{2k}$ new rows ($m$ being the
original number of rows), of which many are redundant. Since the number of
redundant rows increases fast during elimination, removing (most of) them is
highly desirable. In our implementation, we use the property that if $k$
variables have been eliminated, any row derived from more than $k+1$ rows of
the original system is redundant. This result was originally stated by
\cite{cernikov:1963} and rediscovered by \cite{kohler:1967}. A proof can also
be found in \cite{williams:1986}. For the implementation in R, an {\tt
editmatrix} is augmented with an integer $h$, recording the number of
eliminations and a {\tt logical} array $\bf H$, which records for each edit
from which original edit it was derived. Obviously, ${\bf H}$ is {\sc true}
only on the diagonal when $h=0$. It is worth mentioning that by using R's
vectorized indices and recycling properties, it is possible to avoid any
explicit looping in the elimination process. Algorithm \ref{eliminateFM} gives
an overview of the algorithm where explicit loops are included for readability.
Figure \ref{ReliminateFM} shows how one or more variables can be eliminated
from an editmatrix with the {\tt eliminateFM} function.  Note that when
multiple variables are eliminated, the {\tt editmatrix} must be overwritten to
at every iteration to ensure that the history $\bf H$ is updated accordingly.
%

\begin{algorithm}[t]
\caption{{\sc eliminateFM}$(E,j)$. In the actual implementation all explicit loops are avoided by
making use of R's recycling properties and vectorized indices.}
\label{eliminateFM}
\begin{algorithmic}
\Require A normalized {\tt editmatrix} $E=\langle [{\bf A|b}],\boldsymbol{\odot},{\bf H},h\rangle$, and a variable index $j$.
\If {${\bf H}=\varnothing$}
\State ${\bf H}\leftarrow {\rm diag}(${\sc true}$)^m$
\State $h\leftarrow 0$
\EndIf
\State $J\leftarrow \{1,2,\ldots, n+1\}$
\State $I_0\leftarrow \{i\,:\, A_{ij}=0 \}$
\State $I_=\leftarrow \{i\,:\, \odot_i \in\{=\}\}\backslash I_0$
\State $I_+\leftarrow \{i\,:\, A_{ij}>0 \}\backslash I_=$
\State $I_-\leftarrow \{i\,:\, A_{ij}<0 \}\backslash I_=$
\For {$i\in \{1,2,\ldots,m\}\backslash I_{0}$} \Comment{All rows get $j^{\rm th}$ coefficient in $\{-1,0,1\}$}
\If {$\odot_i\in \{<,\leq\}$}
\State  $[{\bf A|b}]_{i,J}\leftarrow [{\bf A|b}]_{i,J}|A_{ii}|^{-1}$
\Else
\State  $[{\bf A|b}]_{i,J}\leftarrow [{\bf A|b}]_{i,J}A_{ii}^{-1}$
\EndIf
\EndFor
\State \Comment{Substitute equalities and inequalities with positive $j^{\rm th}$ coefficient in inequalities
with negative $j^{th}$ coefficient:}
\For {$(i,j)\in (I_=\cup I_+) \times I_-$} 
\State $k\leftarrow k+1$
\State $[\tilde{\bf A}|\tilde{\bf b}]_{k,J}\leftarrow[{\bf A|b}]_{i,J} + [{\bf A|b}]_{j,J}$
\State $\tilde{\bf H}_{k,J}\leftarrow {\bf H}_{i,J}\lor{\bf H}_{j,J}$
\State {\bf if} {${\odot_i}\in\{<\}$ } {\bf then} $\tilde{\odot}_k\leftarrow \odot_i$ {\bf else} $\tilde{\odot}_k\leftarrow\odot_j$
\EndFor
\State\Comment{Substitute equalities in inequalities with positive $j^{\rm th}$ coefficient}
\For {$(i,j)\in I_+\times I_=$}
\State $k\leftarrow k+1$
\State $[\tilde{\bf A}|\tilde{\bf b}]_{k,J}\leftarrow[{\bf A|b}]_{i,J} - [{\bf A|b}]_{j,J}$
\State $\tilde{\bf H}_{k,J}\leftarrow {\bf H}_{i,J}\lor{\bf H}_{j,J}$
\State $\tilde{\odot}_k\leftarrow \odot_i$
\EndFor
\For {$\{(i,j)\in I_=^{\times 2}\,:\,j>i\}$}\Comment{Substitute equalities in equalities}
\State $k\leftarrow k+1$
\State $[\tilde{\bf A}|\tilde{\bf b}]_{k,J}\leftarrow[{\bf A|b}]_{i,J} - [{\bf A|b}]_{j,J}$
\State $\tilde{\bf H}_{k,J}\leftarrow {\bf H}_{i,J}\lor{\bf H}_{j,J}$
\State $\tilde{\odot}_k\leftarrow \odot_i$
\EndFor
\State $\tilde{E}\leftarrow\left\langle\left[\tilde{\bf A}|\tilde{\bf b}]',[{\bf A|b}]_{I_0,J}'\right]',(\tilde{\boldsymbol{\odot}},\boldsymbol{\odot}_{I_0}),\tilde{\bf H},h+1\right\rangle$
\State Remove edit rules of  $\tilde{E}$ which have more than $h+1$ elements of ${\bf H}_{i,J}$ {\sc true}
\State Remove edit rules of $\tilde{E}$ for which {\sc isObviouslyRedundant}$(\tilde{E})$ is {\sc true}
\Ensure {\tt editmatrix} $\tilde{E}$ with variable $j$ eliminated and updated history
\end{algorithmic}
\end{algorithm}
%
\begin{Rcode}
<<>>=
eliminateFM(E,"t")
F <- E
for ( var in c("t","cp","p") ) F <- eliminateFM(F,var)
F
@
\caption{Above: eliminating {\tt t} from the editmatrix with the {\tt eliminateFM} function.
Below: to eliminate multiple variables, the original editmatrix must be overwritten at each
iteration to ensure that the derivation history is updated at every step.}
\label{ReliminateFM}
\end{Rcode}


\section{Error localization for numerical data}
\label{serrorlocalization}
While checking whether a numerical record violates any imposed restrictions
(within a certain limit) is easy, finding out which variable(s) of the record
cause the violation(s) can be far from trivial. When possible, the cause of the
violation, should be sought out, since it leads immediately to repair
suggestions. The {\tt deducorrect} package \citep{loo:2011} mentioned above
offers functionality to detect and repair common errors like typing errors,
rounding errors and sign errors. Although not directly available in R, methods
for detecting repairing unit measure errors or other systematic errors have
been described in literature and may readily be implemented in R (see
\cite{waal:2011} Chapter 2 for an overview). 

After systematic errors with detectable causes in a data set have been
resolved, one may assume that remaining errors are distributed randomly (but
not necessarily uniformly) over one or more of the variables. In that case,
error localization based on the (generalized) principle of Fellegi and Holt can
be applied.


\subsection{The generalized Fellegi-Holt paradigm} 
\label{sgeneralfellegiholt}
In line with the good
practice of altering source data as little as possible, the paradigm of
\cite{fellegi:1976} advises to edit an as small amount of variables as
possible, under the condition that after editing, every edit rule can be
obeyed. A generalization of this principle says that a weighted number
of variables should be minimized. More formally, the principle yields the
following problem. Given a record ${\bf x}$, violating a number of edits
in an edit matrix $E$ (see Eqn. \eqref{editset}) with $m$ rules and $n$ variables, 
find $G$ such that
%
\begin{eqnarray}
\lefteqn{G = \argmin_{g\subset \{1,2,\ldots,n\}} \sum_{j\in g}w_j\delta(x_j,\tilde{x}_j),}\nonumber\\
 && \textrm{such that a solution } \tilde{\bf x}\in\mathbb{R}^{|G|}\textrm{ exists for} \nonumber\\
&& \sum_{j\in G} {A_{ij}}\tilde{x}_{j} \odot_i b_i-\sum_{j\not\in G}A_{ij}x_j,\quad i\in \{1,2,\ldots,m\}.
\label{fhproblem}
\end{eqnarray}
%
In other words, for every variable in $\bf x$, we have to deceide wheter to
adapt it or not. Variables which are not adapted will be replaced with their
value $x_j$ while variables that will be adapted will have to bereplaced by a
value $\tilde{x}_j$, which has to to be determined. The solution to
\eqref{fhproblem} need not be unique, but there is always at least one
solution unless the edit rules in $E$ are contradictory. 

The minimization \eqref{fhproblem} amounts to a binary search problem, of which
the search space increases as $2^n$ ($n$ the number of variables).
\cite{waal:2003} and \cite{waal:2011} describe a branch-and-bound binary search
algorithm which generates all minimal weight solutions. It works by generating
the following binary tree: the root node contains $E$ and $\bf x$ and weight
$w=0$.  Both left and right nodes receive a copy of the objects in their
parents. In the left child node, $x_1$ is assumed correct and its value is
substituted in $E$. In the right child node, $x_1$ is assumed to contain an
error and it is eliminated from $E$ by Fourier-Motzkin elimination. The weight
$w$ in the right node is increased by $w_1$. Each child node gets a left and
right child node where $x_2$ is substituted or eliminated, and so on untill
every variable has been treated.  Every path from root to leave represents one
element of the search space. A branch is pruned when $E$
contains obvious inconsistencies, so no combinations not satisfying the
condition in \eqref{fhproblem} are generated. If a solution, with certain
weight $w$ is found, branches developed later, receiving a higher weight are
pruned as well.

To clarify the above, in the next subsection we give two worked examples.
Subsection \eqref{schoicepoint} describes a flexible binary search algorithm,
which we implememted to support general binary search problems. Subsection
\ref{scpeditmatrix} describes its application to the branch-and-bound algorithm
mentioned above.

\subsection{Two examples}
\begin{figure}
\centering
\includegraphics[width=0.495\textwidth]{diamond}
\includegraphics[width=0.495\textwidth]{twodiamond}
\caption{Graphic representation of editrules and the allowed area. Left panel: a convex
case, as defined by Eq.\ \eqref{E1}. Right panel: the nonconvex nonconnected case, as defined
by Eq.\ \eqref{E2}. Grey areas indicate the valid record domain, black dots indicate erroneous records and 
black arrows indicate the solution of the error localization problem, while the thin black lines
show the range of solutions. The dotted arrows in the left panel indicate the range of directions in which
the record (0,0) can move to reach the valid area.}
\label{example1}
\end{figure}

To illustrate the binary search algorithm outlined above we will consider a
simpe two-dimensional example. The reader is encouraged to follow the reasoning
below by checking the calculations using the R-functions mentioned in the
previous sections. 

Consider a 2-variable record $(x,y)$ subject to the set of constaints $E$:
\begin{equation}
\label{E1}
E = \left\{
\begin{array}{ll}
e_1: & y > x - 1\\
e_2: & y > -x + 3\\
e_3: & y < x + 1\\
e_4: & y < -x + 5. 
\end{array}\right.
\end{equation}
Each separate inequality yields a half-plane of which the borders is determined
by the line obtained by replacing $<$ or $>$ by $=$. The intersection of the
four half-planes is the region of allowed records.  In this example, the region
is a diamond, depicted as the grey area in Figure \ref{example1}.  The borders
are labed with the editrules in Eq.\ \eqref{E1}. Consider the record
$(y=2,x=-1)$, depicted as the bottom black dot in Figure \ref{example1}. It is
easy to confirm either graphically or by substitution that $(2,-1)$ violates
edits $e_1$ and $e_2$, and that the record can be made consistent by altering
only $y$ and leaving $x$ constant (indicated by the black arrow).  It is also
clear from the graph that the allowed values for  $y$ are between $1$ and $3$ 
(indicated by the thin black vertical line in the diamond). The case $(x=0,y=0)$
also violates $e_1$ and $e_2$ and can only be replaired by altering both $x$ and
$y$, while the record $(x=-1,y=2)$ can be repaired by changing $x$ only.

In the following we show that the binary search algorithm described in the
previous subsection indeed solves the error localization problem for
$(x=2,y=-1)$. To find the unweighted, least number of variables to adapt, so
that $E$ can be fulfilled, consider the triple 
\begin{equation}
T_0 = \left\langle E, (2,-1),w=0)\right\rangle,
\end{equation}
This is the root node of the binary search tree described
in the previous subsection, with $w$ the initial solution weight.
The left child is generated by assuming that the first value
in the record is correct. We therefore replace the variable $x$ in
$E$ by its value in the record, which yields after removing redundancies,
\begin{equation}
T_{0l} = \left\langle
\begin{array}{l}
y > 1\\
y < 3
\end{array}, (2,-1),0\right\rangle.
\end{equation}
In this notation, each time a left (right) node is added, the subscribt of $T$ is augmented
with an $l$ ($r$). Substituting one of the values further restricts the possible values
for variables that have not been treated yet. In fact, after the error localization problem
has been solved, subsitituting all unaltered values into $E$ yields a set of equations which 
determine the range of the variable vector which have to be altered or imputed.

Since no variables were eliminated, the weight in $T_{0l}$ is 0, and the record
has not changed.  In the right child of the root, $x$ is assumed to be wrong,
and therefore eliminated  using Fourier-Motzkin elimination:
\begin{equation}
T_{0r}=\left\langle
\begin{array}{l}
y > 1\\
y < 3
\end{array},(x,-1),1\right\rangle.
\end{equation}
The system of equations left after elimination of $x$ illustrates the
geometrical interpretation of Fourier-Motzkin elimination. The range of $y$
corresponds to the projection of the diamond in the left pane of Figure
\ref{example1} onto the $y$-axis. (The fact that $T_{0l}$ yields the same
system is mere coincidence and depends on the fact that the $x$-coordinate in
the record at hand equals 2). Calculating the left child of $T_{0l}$ means
substiting $y$ by $-1$ in the edits of $T_{0l}$.  This yields 
\begin{equation}
T_{0ll} = \left\langle\begin{array}{l}
-1 > 1\\
-1 < 3
\end{array},(2,-1),0\right\rangle,
\end{equation}
where the contradiction $-1>1$ which indicates that $T_{0ll}$ is not a solution (which
is obvious since none of the values in the records are assumed incorrect).
The right child of $T_{0l}$ is obtained by eliminating $y$:
\begin{equation}
T_{0lr} = \left\langle \varnothing, (2,y),1\right\rangle,
\end{equation}
where the tautology $0<2$ was removed. This endnode does represent a solution, since no
conflicting rules have been generated. To see if any other solutions exist, continue to
calculate the left child node of $T_{0r}$
\begin{equation}
T_{0rl} = \left\langle\begin{array}{l}
-1 > 1\\
-1 < 3
\end{array},(x,-1),1
\right\rangle,
\end{equation}
which is no solution since its edits hold a contradiction. The final, right
child node of $T_{0r}$ reads
\begin{equation}
T_{0rr} = \left\langle\varnothing,(x,y),2\right\rangle,
\end{equation}
which also is a solution, but since both $x$ and $y$ have to be adapted, it has
a higher weight than the solution $T_{0lr}$ found earlier. 

The edit sets described so far involved a single set of (in)equalities,  yielding
a convex record domain in $\mathbb{R}^n$. However, in practical cases the sets of
allowed values for a record need not be convex, or even connected. As an example 
consider the space of allowed records, indicated by the grey areas in the right panel
of Figure \ref{example1}. Such a range can be defined by a conditional edit of the
form
\begin{equation}
\textbf{if } e_0:\, x < 0 \textbf{ then }  
\left\{\begin{array}{ll}
e_1:& y > x + 3\\
e_2:& y > -x + 1\\
e_3:& y < x + 5\\
e_4:& y < -x + 1
\end{array}\right.
\textbf{ else }
\left\{\begin{array}{ll}
e_1':&y > x\\
e_2':&y > -x+4\\
e_3':&y <  x+2\\
e_4':&y < -x+6.
\end{array}\right.
\label{E2}
\end{equation}
The error localization problem fo this can be handled by solving the partial
localization problems for $\{e_0,e_1,\ldots,e_4\}$ and $\{
\overline{e}_0,e_1',\ldots,e_4'\}$ separately, where $\overline{e}_0$ stands
for the complement $\overline{e}_0:\, x \geq 0$. The partial solution with the
lowest weight solves the complete optimization problem. As an illustration consider
the record $(x=2,y=0)$ in the right panel of Figure \ref{example1}. The error localization
problem corresponding to $x<0$ yields a solution where both $x$ and $y$ have to be altered,
while the localization problem corresponding to $x\geq 0$ implies that only $y$ needs to be
altered.

To generalize this example, note that a conditional edit sets of the form
\begin{equation}
\textbf{if } E_0\textbf{ then } E_1\textbf{ else } E_2,
\end{equation}
can be written as
\begin{equation}
(E_0 \land E_1)\lor (\overline{E}_0\land E_2)
\label{editexpansion}
\end{equation}
which may be treated by finding the minimum weight solution between the solutions generated
by $E_0\land E_1$ and $\overline{E}_0\land E_2$. Taking the complement can cause
the number of partial localization problems to grow quickly. As an illustration, consider the
following case where taking the complement yields three cases to be treated by the
error localization routine.
\begin{eqnarray}
\lefteqn{
\textbf{if } (x=0) \textbf{ then } E_1\textbf{ else } E_2}\nonumber\\
&\Leftrightarrow& ((x=0) \land E_1) \lor ((x\not=0)\land E_2)\nonumber\\
&\Leftrightarrow& ((x=0) \land E_1) \lor ((x < 0)\land E_2) \lor ((x>0)\land E_2).
\label{exampleExpansion}
\end{eqnarray}
The number of partial error localization problems to be treated
grows as $2n_{\rm eq}+n_{\rm ineq}$, where $n_{\rm eq}$ is the number
of equalities and $n_{\rm ineq}$ the number of inequalities in $E_0$.
This is easily derived from Eq.\ \eqref{editexpansion} since by De Morgan's law
\begin{equation}
\overline{E}_0=\overline{e_1\land e_2\land\ldots \land e_k} 
= \overline{e}_1\lor\overline{e}_2\lor\ldots\lor\overline{e}_k.
\end{equation}
Here, each negated inequality translates to a single inequality, while each negated
equality yields two inequalities (as in Eq.\ \eqref{exampleExpansion}).

We will have more to say on conditional edits in the accompanying paper where
the error localization problem for categorical and mixed data are treated.

\subsection{General binary search with the {\tt choicepoint} object}
\label{schoicepoint}
As stated in subsection \ref{sgeneralfellegiholt}, the error localization
problem can be interpreted as a (pruned) binary programming problem. To
facilitate implementation of error localization for numerical, categorical and
mixed data, as well as to help further research in error localization
algorithms it was deceided to implement general-purpose binary search
functionality in the form of binary choice point programming.

The term ``choice point'' stems from the field of nondeterministic programming.
In nondeterministic programming, the control flow of a program is not
determined explicitly by the programmer with standard branching statements. In
stead, choice points may be created which store the full state of a program so
that control flow can at any time return to a stored state and choose a new
path from there. Choice point programming is supported by various niche
programming environments, such as {\sf Alma-0} \citep{partington:1997} and {\sf
ELAN} \citep{vittek:1996}. See \cite{moreau:1998} for a clear introduction or
\cite{mart:2002} for a bibliographic overview. The choice point paradigm offers
an excellent environment for programming backtracking algorithms, of which the
Branch-and-Bound algorithm of subsection \ref{sgeneralfellegiholt} is just a
specific example. Moreover, {\sf R} is ideally suited to develop choice
point-like systems since {\sf R} has first-class environments. An {\sf R}
environment can be thought of as a list of name-value pairs of {\sf R} objects,
which are used when evaluating expressions. Expressions may create delete and
remove {\sf R} objects within an environment, and having first-class
environments means that environments can be created, deleted and manipulated
like any other {\sf R} object. {\sf R} environments are therefore employed to
store state information in a choice point.


\begin{algorithmic}
\Require Expressions $\phi_0$, $\phi_l$, $\phi_r$, an expression $\psi$, with
\begin{displaymath}
\psi(\mathcal{E}) = \left\{\begin{array}{ll}
\textrm{\sc true} &\textrm{ if environment } \mathcal{E}\textrm{ contains a solution}\\
\textrm{\sc false}&\textrm{ if environment } \mathcal{E}\textrm{ cannot lead to a solution}\\
\textrm{\sc null}&\textrm{ if environment } \mathcal{E}\textrm{ contains no solution}
\end{array}\right.
\end{displaymath}
\State $\mathcal{E}\leftarrow\phi_0(\mathcal{E}_0)$ \Comment{$\phi_0$ can be used for variable initialisation}
\State $\mathcal{E}::\textrm{treatedleft}\leftarrow \textrm{\sc false}$
\State $\mathcal{E}::\textrm{treatedright}\leftarrow \textrm{\sc false}$
\While{$\psi(\mathcal{E})\in\{\textrm{\sc false},\textrm{\sc null}\} \land \mathcal{E}\not=\textrm{\sc null}$ }
\State $\textrm{\sc push }\mathcal{E}$
\If{$\neg\mathcal{E}::\textrm{treatedleft}$}
\State $\mathcal{E}::\textrm{treatedleft}\leftarrow \textrm{\sc true}$
\State $\textrm{\sc push }\phi_l(\mathcal{E})$
\ElsIf{$\neg\mathcal{E}::\textrm{treatedright}$}
\State $\mathcal{E}::\textrm{treatedright}\leftarrow \textrm{\sc true}$
\State $\textrm{\sc push }\phi_r(\mathcal{E})$
\EndIf
\State $\textrm{\sc pop}$
\EndWhile
\Return $\mathcal{E}$
\end{algorithmic}









\subsection{Error localization with {\tt cp.editmatrix}}
\label{scpeditmatrix}

\section{Conclusions}

\newpage

\bibliographystyle{chicago}
\bibliography{editrules}


\end{document}
