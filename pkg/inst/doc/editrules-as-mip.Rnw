%\VignetteIndexEntry{Error localization for numerical and categorical edits as a mixed integer problem}
\documentclass[11pt, fleqn, a4paper]{article}
\usepackage[english]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{threeparttable}
\usepackage{natbib}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage{threeparttable}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\Lor}{\lor}
\DeclareMathOperator*{\Land}{\land}
\DeclareMathOperator{\res}{\mathfrak{R}}
\newcommand{\rhomap}{\xrightarrow{\rho}}

\newtheorem{theorem}{Theorem}

\usepackage{float} 
 
\floatstyle{boxed}
\newfloat{Rcode}{t}{rco}
\floatname{Rcode}{Figure}



% stimulate latex to put multiple floats on a page.
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{3}
\setcounter{dbltopnumber}{2}
\renewcommand{\topfraction}{.9}
\renewcommand{\textfraction}{.1}
\renewcommand{\bottomfraction}{.75}
\renewcommand{\floatpagefraction}{.9}
\renewcommand{\dblfloatpagefraction}{.9}
\renewcommand{\dbltopfraction}{.9}
\hyphenation{time-stamp}

<<echo=false>>=
library(editrules)
@

\title{Error localization as a mixed integer problem with the {\tt editrules} package\\
{\small package version \Sexpr{packageVersion("editrules")}}}
\author{Edwin de Jonge and Mark van der Loo}
\begin{document}
\maketitle
\begin{abstract}
{\em This vignette is far from finished. Version 2.0 of the package will have
the full vignette. At the moment, functionality for solving error localization problems
with lp solvers is experimental.}
\end{abstract}

\newpage
\tableofcontents
\newpage

\section{Introduction}
Analyses of real data are often hindered by occurrences of incomplete or
inconsistent raw data records.  The process of locating and correcting such
errors is referred to as {\em data editing}, and it has been estimated that
National Statistics Institutes spend up to 40\% of their resources on this
process \citep{waal:2011}. For this reason, considerable attention is paid to
the development of data editing methods that can be automated. Since data are
often required to obey many interrelated consistency rules, data
editing can be too complex to perform manually. \citet{winkler:1999} mentions
practical cases where records have to obey 250, 300 or even 750 internal
consistency rules.  Although the {\sf R} statistical environment has numerous
facilities for analyzing categorical data [See {\em e.g.} \citet{husson:2010}],
the options for error localization and record correction are currently limited.

The {\sf R} package {\sf editrules} was
developed to help closing the gap between raw data retrieval and data analysis
with {\sf R}.  The main purpose of the {\sf editrules} package is to provide a
user-friendly environment for handling data restriction rules, to apply those
rules to data, and to localize erroneous fields in data based on the
generalized principle of \cite{fellegi:1976}.  The package does not offer
functionality for data correction. However, it does facilitate the
identification of the set of solutions for an error correction problem. 
For a detailed description we refer to \cite{jonge:2011} and \cite{loo:2011b}.

{\sf editrules} offers a fairly complete toolbox to work with numerical and categorical edits.
It contains a flexible object for localizing errors, which can be adapted by the user of {\sf editrules} based on a branch and bound
algorithm (ref Waal).
However, for the time to solve the error localization problem with a branch and bound algorithm grows exponentially with the number of (incorrect) variables. Many surveys have hundreds of variables, which results in (very) long processing times for records with many errors. 

This paper describes the error localization problem for numerical and categorical edits as a mixed integer problem and its implementation in {\sf editrules}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SECTION 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Mixed integer programming}
Definition of a mixed integer program.

description of lpSolveAPI.

\section{Numerical data errors}

Any such restriction can be written in the form
\begin{equation}
\label{edit}
{\bf \a\cdot{\bf x} \odot b\textrm{ with }\odot\in\{<,\leq,=\},
\end{equation}
where $\bf x$ is a numerical data record, ${\bf a}$, ${\bf x}\in \mathbb{R}^n$
and $b\in \mathbb{R}$. In data editing literature, data restriction rules are
referred to as {\em edits}, or {\em edit rules}\index{edit rules}\index{edit}.
In this paper we will call edits, written in the form of Eq.\ \eqref{edit}
(specifically, without using $\geq$ or $>$),
edits in {\em normal form}\index{edit rules!normal form}. 


Numerical variables are always bounded in practice, e.g. age, income, height.
In our formulation of the error localization problem as a mixed integer 
problem we use the boundaries explicitly: first of all it allows for easy 
to understand and to implement equations. Secondly our formulation improves 
numerical stability of the MIP for suitable choosen boundaries. 

The record ${\bf x} = (x_1,\dots,x_m)$ to be validated 
has the following reported (numerical) values, that may be incorrect:
\begin{equation}
x_i = {\rm c}_i \label{eq:values}
\end{equation}
under the restriction of
\begin{equation}
{\bf a}\cdot{\bf x} \odot b\textrm{ with }\odot\in\{<,\leq,=\}
\end{equation}

We assume each variable $x_i$ is bounded by $l_i$ and $u_i$
\begin{equation}
l_i \leq x_i \leq u_i \label{eq:boundary}
\end{equation}

For each variable $x_i$ we introduce a binary variable $d_i \in \{0,1\}$ and we add two edits 
to the original edit matrix that conditionally constrain the value of $x_i$ to $c_i$ 

\begin{eqnarray}
x_i &\leq& c_i + (u_i - c_i)d_i \\
(l_i - c_i)d_i + c_i &\leq& x_i
\end{eqnarray}
Variable $d_i$ signifies if $x_i$ should be adapted: if $d_i = 0$ these edits reduce to equation \ref{eq:values}, meaning
that the reported $c_i$ is assumed correct. When $d_i = 1$ the edits reduce to equation \ref{eq:boundary}, meaning that
the value of $x_i$ is unconstrained and can take any feasible value.

The principle of Felligi Holt \cite{} is to minimize the weigthed sum of adaptations.

The error localization problem can now be formulated as the folowing mixed integer problem:

Minimize $\sum^m_{j=1} w_j d_j$, with:
\begin{equation}
\begin{array}{rcrcl}
\sum^m_{j=1} a_{1j} x_j &&                  &\odot_1& b_1    \\
\ldots                 &&                  &\ldots& \ldots  \\
\sum^m_{j=1}a_{nj} x_j &&                  &\odot_n& b_n    \\
    x_1 &-& u^*_1 d_1   &\leq   & c_1 \\
   -x_1 &+& l^*_1 d_1  &\leq   & -c_1 \\
\ldots  & & \ldots          &       & \ldots \\
    x_m &-& u^*_m d_m   &\leq   & c_m \\
   -x_m &+& l^*_m d_m  &\leq   & -c_m

\end{array}
\end{equation}

with $u^*_i = u_i - c_i$ and $l^*_i = l_i - c_i$.

For large values of  $\beta^*_i$ or $\alpha^*_i$ the resulting MIP problem becomes numerical unstable
so it is wise to choose suitable boundaries, which we will discuss later on.

\subsection{Implementation}
We will use {\tt lpSolveAPI} to solve the mix integer problem. Other candidates are {\tt glpk}
will extend an existing {\tt editmatrix} with the edits and give the 

\section{Categorical data errors}
In (ref naar categorical edit paper) we choose an boolean representation for categorical edits.
To solve the error localization problem for (purely) categorical edits we have to formulate categorical
edits as a integer problem.

\subsection{formulation}
Each edit should hold (conjunction) and each edit states that at least one statement has to be true.
An categorical editmatrix can be seen as a conjunction of disjunctions: it is in conjunctive normal form (reference). 

* Write a categorical variable as a disjunction of boolean variables for each category, with the restriction that their sum is atmost 1. (equals 1 for a closed domain).

* each edit can be written as a disjunction of statements

* each disjunction can be written as a numerical edit where at least one of the variables has to be one

\begin{equation}
A \in {a_j} \lor B \in {b_k}
\end{equation}

$$\lnot (A \in {a_j})$$

* error localizing edits: for each variable $c_i$ $c^{c_i}$, introduce an edit
with $d_i = 1 - c^{c_i}$. When $d_i = 0$,  $c_i = c_{i}$, meaning that the
reported value of $c_i$ is assumed correct,  When $d_i = 1$, $c^c_i = 0$,
meaning that $c_i$ should be adapted.

\subsection{Open vs close domains}

\section{Boundary heuristics}
\subsection{From data set}
Minimum and maximum value of each variable in the data set to be checked gives reasonable boundaries for the dataset. 
\subsection{From observation, per record}
Assume that maximum values for each observation differ at most a factor $f$ (e.g. 1000) of the reported value.

\section{Discussion}

Is a usefull addition to {\tt editrules}, finds quickly solutions to error localization  problems with 
hundreds to thousands of variables. 

Solutions given by current lp solvers can be numerical unstable, which may result in a false positive 
or a false negative solution. Luckily {\tt editrules} contains {\tt substValue} and {\tt isFeasible} 
that can be used together to check the validity of a solution. Furthermore several heuristics can be 
used to increase the numerical stability by using smaller boundaries for the variables.

\subsection{Comparison to {\tt backtracker}}
errorLocalizer is more complete, offers a more complete tool box for finding an optimal solution.
It can also find more equivalent solutions, which is not possible or difficult with MIP solvers.

However when speed of finding a solution matters, it is
\subsection{Previous work}

\bibliographystyle{chicago}
\bibliography{editrules}

\end{document}
